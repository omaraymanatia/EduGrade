{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:24:51.965140Z",
     "iopub.status.busy": "2025-04-18T15:24:51.964907Z",
     "iopub.status.idle": "2025-04-18T15:25:23.728301Z",
     "shell.execute_reply": "2025-04-18T15:25:23.727577Z",
     "shell.execute_reply.started": "2025-04-18T15:24:51.965120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 15:25:10.165427: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744989910.408370      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744989910.474921      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    BitsAndBytesConfig,\n",
    "    TFAutoModel\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Connect to GPU (make sure you've selected GPU in Colab)\n",
    "assert torch.cuda.is_available(), \"Change runtime type to GPU!\"\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:25:23.731991Z",
     "iopub.status.busy": "2025-04-18T15:25:23.731740Z",
     "iopub.status.idle": "2025-04-18T15:25:27.621840Z",
     "shell.execute_reply": "2025-04-18T15:25:27.621097Z",
     "shell.execute_reply.started": "2025-04-18T15:25:23.731964Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea24ec7dbc2f48f89067a409814c1510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100d925fbbeb4fb8beb4bd28a2d28e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744989925.901940      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModel.from_pretrained(\"bert-base-uncased\") #BERT Base model with 110M Parameter and 12 encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:25:27.623428Z",
     "iopub.status.busy": "2025-04-18T15:25:27.623174Z",
     "iopub.status.idle": "2025-04-18T15:25:28.937228Z",
     "shell.execute_reply": "2025-04-18T15:25:28.936627Z",
     "shell.execute_reply.started": "2025-04-18T15:25:27.623400Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db06e16d56b04f3c937ae1cefaaf3232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb213560fa9d418cb81f46ee4f0f7dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecd56a7ea3e401a9a173f439d40ac8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:25:28.938519Z",
     "iopub.status.busy": "2025-04-18T15:25:28.938265Z",
     "iopub.status.idle": "2025-04-18T15:25:28.948192Z",
     "shell.execute_reply": "2025-04-18T15:25:28.947580Z",
     "shell.execute_reply.started": "2025-04-18T15:25:28.938499Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2088, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer('Hello world')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:25:29.365285Z",
     "iopub.status.busy": "2025-04-18T15:25:29.364906Z",
     "iopub.status.idle": "2025-04-18T15:25:40.815306Z",
     "shell.execute_reply": "2025-04-18T15:25:40.814690Z",
     "shell.execute_reply.started": "2025-04-18T15:25:29.365259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a28ee592094117ba3d3f56febd1c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/588 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca342744edb47c189c26d5d7d34f2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00002.parquet:   0%|          | 0.00/287M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7289bdad41f473190305e0c1e8d3db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00002.parquet:   0%|          | 0.00/286M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc043935758c43a186c5361fa379dfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2391ade9274c68afbf8f5116caf3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/610767 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38017921c897408fb5d3e37f544bdc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/261758 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'source', 'sub_source', 'lang', 'model', 'label', 'text'],\n",
      "        num_rows: 610767\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['id', 'source', 'sub_source', 'lang', 'model', 'label', 'text'],\n",
      "        num_rows: 261758\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"Jinyan1/COLING_2025_MGT_en\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:25:40.816554Z",
     "iopub.status.busy": "2025-04-18T15:25:40.816279Z",
     "iopub.status.idle": "2025-04-18T15:25:40.821397Z",
     "shell.execute_reply": "2025-04-18T15:25:40.820864Z",
     "shell.execute_reply.started": "2025-04-18T15:25:40.816535Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'source', 'sub_source', 'lang', 'model', 'label', 'text'],\n",
       "        num_rows: 610767\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'source', 'sub_source', 'lang', 'model', 'label', 'text'],\n",
       "        num_rows: 261758\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:25:40.822299Z",
     "iopub.status.busy": "2025-04-18T15:25:40.822090Z",
     "iopub.status.idle": "2025-04-18T15:25:40.836078Z",
     "shell.execute_reply": "2025-04-18T15:25:40.835487Z",
     "shell.execute_reply.started": "2025-04-18T15:25:40.822284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:25:40.838041Z",
     "iopub.status.busy": "2025-04-18T15:25:40.837810Z",
     "iopub.status.idle": "2025-04-18T15:32:26.894079Z",
     "shell.execute_reply": "2025-04-18T15:32:26.893358Z",
     "shell.execute_reply.started": "2025-04-18T15:25:40.838024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50c97dcb4eb464e953903fb9aece60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/610767 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95793c362700492b9b4ab727242d55c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/261758 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process with maximum efficiency\n",
    "dataset_encoded = dataset.map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    "    remove_columns=['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:32:26.895304Z",
     "iopub.status.busy": "2025-04-18T15:32:26.895094Z",
     "iopub.status.idle": "2025-04-18T15:32:26.900814Z",
     "shell.execute_reply": "2025-04-18T15:32:26.900118Z",
     "shell.execute_reply.started": "2025-04-18T15:32:26.895283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'source', 'sub_source', 'lang', 'model', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 610767\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'source', 'sub_source', 'lang', 'model', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 261758\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:32:26.902035Z",
     "iopub.status.busy": "2025-04-18T15:32:26.901763Z",
     "iopub.status.idle": "2025-04-18T15:32:27.510782Z",
     "shell.execute_reply": "2025-04-18T15:32:27.510204Z",
     "shell.execute_reply.started": "2025-04-18T15:32:26.902013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_tf_dataset = dataset_encoded['train'].to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask', 'token_type_ids'],\n",
    "    label_cols=['label'],\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "val_tf_dataset = dataset_encoded['dev'].to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask', 'token_type_ids'],\n",
    "    label_cols=['label'],\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:39:14.128967Z",
     "iopub.status.busy": "2025-04-18T15:39:14.128221Z",
     "iopub.status.idle": "2025-04-18T15:39:14.133725Z",
     "shell.execute_reply": "2025-04-18T15:39:14.132823Z",
     "shell.execute_reply.started": "2025-04-18T15:39:14.128934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class BERTForClassification(tf.keras.Model):  # Fixed class name typo\n",
    "    def __init__(self, bert_model, num_classes):  # Fixed __init__ syntax\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')  # Fixed to layers (not layer)\n",
    "    def call(self, inputs):\n",
    "        # Assuming inputs is a dict containing input_ids, attention_mask, and token_type_ids\n",
    "        x = self.bert(inputs)[1]  # This might need adjustment based on the actual output structure\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:39:14.982936Z",
     "iopub.status.busy": "2025-04-18T15:39:14.982341Z",
     "iopub.status.idle": "2025-04-18T15:39:14.999546Z",
     "shell.execute_reply": "2025-04-18T15:39:14.998863Z",
     "shell.execute_reply.started": "2025-04-18T15:39:14.982915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create and compile the classifier\n",
    "classifier = BERTForClassification(model, num_classes=2)\n",
    "classifier.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "import time\n",
    "\n",
    "def keep_kaggle_alive():\n",
    "    display(Javascript('''\n",
    "        function KeepAlive() {\n",
    "            console.log(\"Kaggle heartbeat: \" + new Date().toISOString());\n",
    "            document.querySelector(\"body\").dispatchEvent(new KeyboardEvent(\"keydown\", {key: \" \", keyCode: 32}));\n",
    "        }\n",
    "        setInterval(KeepAlive, 30 * 1000);  // Ping every 30 seconds\n",
    "    '''))\n",
    "    \n",
    "keep_kaggle_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:39:24.309839Z",
     "iopub.status.busy": "2025-04-18T15:39:24.309183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   44/19087 [..............................] - ETA: 5:04:12 - loss: 0.4853 - accuracy: 0.7784"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'model_epoch_{epoch:02d}.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=False,\n",
    "        save_weights_only=True\n",
    "    ),\n",
    "    tf.keras.callbacks.CSVLogger('training_log.csv'),  # Logs metrics to a file\n",
    "    tf.keras.callbacks.LambdaCallback(\n",
    "        on_epoch_end=lambda epoch, logs: print(f\"Epoch {epoch} completed at {time.ctime()}\")\n",
    "    )\n",
    "]\n",
    "\n",
    "history = classifier.fit(\n",
    "    train_tf_dataset,\n",
    "    validation_data=val_tf_dataset,\n",
    "    epochs=1,  # Let EarlyStopping handle termination\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-18T15:39:09.431428Z",
     "iopub.status.idle": "2025-04-18T15:39:09.431675Z",
     "shell.execute_reply": "2025-04-18T15:39:09.431580Z",
     "shell.execute_reply.started": "2025-04-18T15:39:09.431570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-18T15:39:09.433070Z",
     "iopub.status.idle": "2025-04-18T15:39:09.433364Z",
     "shell.execute_reply": "2025-04-18T15:39:09.433218Z",
     "shell.execute_reply.started": "2025-04-18T15:39:09.433208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = classifier.fit(\n",
    "    train_tf_dataset,\n",
    "    validation_data=val_tf_dataset,\n",
    "    epochs=5,  # You may want to adjust this\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-18T15:39:09.434613Z",
     "iopub.status.idle": "2025-04-18T15:39:09.434965Z",
     "shell.execute_reply": "2025-04-18T15:39:09.434801Z",
     "shell.execute_reply.started": "2025-04-18T15:39:09.434786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Evaluate on validation set\n",
    "# results = classifier.evaluate(val_tf_dataset)\n",
    "# print(f\"Validation Loss: {results[0]:.4f}\")\n",
    "# print(f\"Validation Accuracy: {results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
