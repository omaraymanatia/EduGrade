{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470dfbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar-ayman/anaconda3/envs/gradenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at OU-Advacheck/deberta-v3-base-daigenc-mgt1a and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"OU-Advacheck/deberta-v3-base-daigenc-mgt1a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a9a662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at OU-Advacheck/deberta-v3-base-daigenc-mgt1a and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"OU-Advacheck/deberta-v3-base-daigenc-mgt1a\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"OU-Advacheck/deberta-v3-base-daigenc-mgt1a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718611ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_to_test = [\n",
    "    \"\"\"Data science is the process of analyzing and interpreting large amounts of data to discover useful insights. It involves collecting data from various sources, cleaning and organizing it to remove errors or inconsistencies, and then exploring it to identify patterns and trends. This exploration often includes visualizations and statistical summaries. After understanding the data, data scientists create models using techniques from machine learning and statistics to make predictions or decisions. These models are evaluated to ensure they are accurate and reliable. The final insights are usually communicated to stakeholders through reports or dashboards, helping guide business strategies or automate systems.\n",
    "\"\"\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a4dcbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(texts_to_test, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac17b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits.numpy()\n",
    "    # Apply softmax to get normalized probabilities that sum to 1\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "\n",
    "human_prob, ai_prob = probabilities[0]\n",
    "# Convert to percentages\n",
    "human_percentage = human_prob * 100\n",
    "ai_percentage = ai_prob * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27fc2ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities (human, machine): 0.42224014 0.57775986\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilities (human, machine):\", human_prob, ai_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99dc6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple threshold for AI detection\n",
    "AI_THRESHOLD = 50.0  # threshold for AI classification\n",
    "\n",
    "# Calculate percentage difference\n",
    "percentage_diff = abs(ai_percentage - human_percentage)\n",
    "\n",
    "# Determine confidence level based on difference\n",
    "if percentage_diff <= 40:\n",
    "    confidence = \"Low\"\n",
    "elif percentage_diff <= 70:\n",
    "    confidence = \"Medium\"\n",
    "else:\n",
    "    confidence = \"High\"\n",
    "\n",
    "# Classification logic\n",
    "if ai_percentage >= AI_THRESHOLD:\n",
    "    label = \"AI\"\n",
    "else:\n",
    "    label = \"Human\"\n",
    "\n",
    "if confidence == \"Low\":\n",
    "    label = \"Uncertain but it is likely to be\" + \" \" + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fecf4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection Results\n",
      "----------------------------------------\n",
      "Human Probability: 42.2%\n",
      "AI Probability: 57.8%\n",
      "----------------------------------------\n",
      "Classification: Uncertain but it is likely to be AI\n",
      "Confidence: Low\n"
     ]
    }
   ],
   "source": [
    "print(f\"Detection Results\")\n",
    "print(f\"{'-'*40}\")\n",
    "print(f\"Human Probability: {human_percentage:.1f}%\")\n",
    "print(f\"AI Probability: {ai_percentage:.1f}%\")\n",
    "print(f\"{'-'*40}\")\n",
    "print(f\"Classification: {label}\")\n",
    "print(f\"Confidence: {confidence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
